{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ArcaneGAN inference.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JacopoMangiavacchi/.net3gRPCTest/blob/master/ArcaneGAN_inference.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yzYVMxTPTdmw"
      },
      "source": [
        "An inference notebook for [ArcaneGAN v0.3](https://github.com/Sxela/ArcaneGAN/releases/tag/v0.3).\n",
        "Made by [Alex Spirin](https://twitter.com/devdef)\n",
        "\n",
        "If you like what I'm doing you can tip me [here](https://donationalerts.com/r/derplearning) or follow on [Patreon](https://www.patreon.com/sxela)\n",
        "\n",
        "![visitors](https://visitor-badge.glitch.me/badge?page_id=sxela_arcanegan)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I9ikXFtITiuK",
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        },
        "outputId": "89fc0c44-049e-4d56-f91e-c5b57000eb2e"
      },
      "source": [
        "#@title This colab is distributed under the MIT license\n",
        "\"\"\"MIT License\n",
        "\n",
        "Copyright (c) 2021 Alex Spirin\n",
        "\n",
        "Permission is hereby granted, free of charge, to any person obtaining a copy\n",
        "of this software and associated documentation files (the \"Software\"), to deal\n",
        "in the Software without restriction, including without limitation the rights\n",
        "to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n",
        "copies of the Software, and to permit persons to whom the Software is\n",
        "furnished to do so, subject to the following conditions:\n",
        "\n",
        "The above copyright notice and this permission notice shall be included in all\n",
        "copies or substantial portions of the Software.\n",
        "\n",
        "THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n",
        "IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n",
        "FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n",
        "AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n",
        "LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n",
        "OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\n",
        "SOFTWARE.\"\"\""
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'MIT License\\n\\nCopyright (c) 2021 Alex Spirin\\n\\nPermission is hereby granted, free of charge, to any person obtaining a copy\\nof this software and associated documentation files (the \"Software\"), to deal\\nin the Software without restriction, including without limitation the rights\\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\\ncopies of the Software, and to permit persons to whom the Software is\\nfurnished to do so, subject to the following conditions:\\n\\nThe above copyright notice and this permission notice shall be included in all\\ncopies or substantial portions of the Software.\\n\\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\\nSOFTWARE.'"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GXqfcKRpS5Bi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e91f4ff4-b8c7-454f-9f79-93780a3c6108"
      },
      "source": [
        "#@title Install and download. Run once.\n",
        "#release v0.2\n",
        "!wget https://github.com/Sxela/ArcaneGAN/releases/download/v0.1/ArcaneGANv0.1.jit\n",
        "!wget https://github.com/Sxela/ArcaneGAN/releases/download/v0.2/ArcaneGANv0.2.jit\n",
        "!wget https://github.com/Sxela/ArcaneGAN/releases/download/v0.3/ArcaneGANv0.3.jit\n",
        "!pip -qq install facenet_pytorch"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2021-12-15 19:54:30--  https://github.com/Sxela/ArcaneGAN/releases/download/v0.1/ArcaneGANv0.1.jit\n",
            "Resolving github.com (github.com)... 140.82.121.3\n",
            "Connecting to github.com (github.com)|140.82.121.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://objects.githubusercontent.com/github-production-release-asset-2e65be/435295742/382acf3d-4259-4419-8eed-10fed3980c09?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20211215%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20211215T195430Z&X-Amz-Expires=300&X-Amz-Signature=355d04cfd906730ea56ecdd7a30aacb3dcf46a0826ed1449732349db0655417f&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=435295742&response-content-disposition=attachment%3B%20filename%3DArcaneGANv0.1.jit&response-content-type=application%2Foctet-stream [following]\n",
            "--2021-12-15 19:54:30--  https://objects.githubusercontent.com/github-production-release-asset-2e65be/435295742/382acf3d-4259-4419-8eed-10fed3980c09?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20211215%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20211215T195430Z&X-Amz-Expires=300&X-Amz-Signature=355d04cfd906730ea56ecdd7a30aacb3dcf46a0826ed1449732349db0655417f&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=435295742&response-content-disposition=attachment%3B%20filename%3DArcaneGANv0.1.jit&response-content-type=application%2Foctet-stream\n",
            "Resolving objects.githubusercontent.com (objects.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to objects.githubusercontent.com (objects.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 83394634 (80M) [application/octet-stream]\n",
            "Saving to: ‘ArcaneGANv0.1.jit’\n",
            "\n",
            "ArcaneGANv0.1.jit   100%[===================>]  79.53M  18.5MB/s    in 4.7s    \n",
            "\n",
            "2021-12-15 19:54:36 (16.8 MB/s) - ‘ArcaneGANv0.1.jit’ saved [83394634/83394634]\n",
            "\n",
            "--2021-12-15 19:54:36--  https://github.com/Sxela/ArcaneGAN/releases/download/v0.2/ArcaneGANv0.2.jit\n",
            "Resolving github.com (github.com)... 140.82.121.4\n",
            "Connecting to github.com (github.com)|140.82.121.4|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://objects.githubusercontent.com/github-production-release-asset-2e65be/435295742/52b19f21-13c4-49ea-b920-34d22f01f71b?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20211215%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20211215T195436Z&X-Amz-Expires=300&X-Amz-Signature=c9085bd09eb8617e4cc4bd9b508b725e11d4eed66695161183d1d947b0eca498&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=435295742&response-content-disposition=attachment%3B%20filename%3DArcaneGANv0.2.jit&response-content-type=application%2Foctet-stream [following]\n",
            "--2021-12-15 19:54:36--  https://objects.githubusercontent.com/github-production-release-asset-2e65be/435295742/52b19f21-13c4-49ea-b920-34d22f01f71b?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20211215%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20211215T195436Z&X-Amz-Expires=300&X-Amz-Signature=c9085bd09eb8617e4cc4bd9b508b725e11d4eed66695161183d1d947b0eca498&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=435295742&response-content-disposition=attachment%3B%20filename%3DArcaneGANv0.2.jit&response-content-type=application%2Foctet-stream\n",
            "Resolving objects.githubusercontent.com (objects.githubusercontent.com)... 185.199.109.133, 185.199.110.133, 185.199.111.133, ...\n",
            "Connecting to objects.githubusercontent.com (objects.githubusercontent.com)|185.199.109.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 83386102 (80M) [application/octet-stream]\n",
            "Saving to: ‘ArcaneGANv0.2.jit’\n",
            "\n",
            "ArcaneGANv0.2.jit   100%[===================>]  79.52M  27.7MB/s    in 2.9s    \n",
            "\n",
            "2021-12-15 19:54:39 (27.7 MB/s) - ‘ArcaneGANv0.2.jit’ saved [83386102/83386102]\n",
            "\n",
            "--2021-12-15 19:54:39--  https://github.com/Sxela/ArcaneGAN/releases/download/v0.3/ArcaneGANv0.3.jit\n",
            "Resolving github.com (github.com)... 140.82.121.3\n",
            "Connecting to github.com (github.com)|140.82.121.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://objects.githubusercontent.com/github-production-release-asset-2e65be/435295742/7751d68c-f131-494d-842c-fd6a94a8c56f?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20211215%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20211215T195439Z&X-Amz-Expires=300&X-Amz-Signature=269d166660a9275ac5e2ce9138e8a7bca5c71271372c0d38c5178ed01911022f&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=435295742&response-content-disposition=attachment%3B%20filename%3DArcaneGANv0.3.jit&response-content-type=application%2Foctet-stream [following]\n",
            "--2021-12-15 19:54:40--  https://objects.githubusercontent.com/github-production-release-asset-2e65be/435295742/7751d68c-f131-494d-842c-fd6a94a8c56f?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20211215%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20211215T195439Z&X-Amz-Expires=300&X-Amz-Signature=269d166660a9275ac5e2ce9138e8a7bca5c71271372c0d38c5178ed01911022f&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=435295742&response-content-disposition=attachment%3B%20filename%3DArcaneGANv0.3.jit&response-content-type=application%2Foctet-stream\n",
            "Resolving objects.githubusercontent.com (objects.githubusercontent.com)... 185.199.111.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to objects.githubusercontent.com (objects.githubusercontent.com)|185.199.111.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 83258790 (79M) [application/octet-stream]\n",
            "Saving to: ‘ArcaneGANv0.3.jit’\n",
            "\n",
            "ArcaneGANv0.3.jit   100%[===================>]  79.40M  24.5MB/s    in 3.2s    \n",
            "\n",
            "2021-12-15 19:54:43 (24.5 MB/s) - ‘ArcaneGANv0.3.jit’ saved [83258790/83258790]\n",
            "\n",
            "\u001b[K     |████████████████████████████████| 1.9 MB 12.7 MB/s \n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mm7x7XgxUUwv"
      },
      "source": [
        "#@title Define functions\n",
        "#@markdown Select model version and run.\n",
        "from facenet_pytorch import MTCNN\n",
        "from torchvision import transforms\n",
        "import torch, PIL\n",
        "\n",
        "from tqdm.notebook import tqdm\n",
        "\n",
        "mtcnn = MTCNN(image_size=256, margin=80)\n",
        "\n",
        "# simplest ye olde trustworthy MTCNN for face detection with landmarks\n",
        "def detect(img):\n",
        " \n",
        "        # Detect faces\n",
        "        batch_boxes, batch_probs, batch_points = mtcnn.detect(img, landmarks=True)\n",
        "        # Select faces\n",
        "        if not mtcnn.keep_all:\n",
        "            batch_boxes, batch_probs, batch_points = mtcnn.select_boxes(\n",
        "                batch_boxes, batch_probs, batch_points, img, method=mtcnn.selection_method\n",
        "            )\n",
        " \n",
        "        return batch_boxes, batch_points\n",
        "\n",
        "# my version of isOdd, should make a separate repo for it :D\n",
        "def makeEven(_x):\n",
        "  return _x if (_x % 2 == 0) else _x+1\n",
        "\n",
        "# the actual scaler function\n",
        "def scale(boxes, _img, max_res=1_500_000, target_face=256, fixed_ratio=0, max_upscale=2, VERBOSE=False):\n",
        " \n",
        "    x, y = _img.size\n",
        " \n",
        "    ratio = 2 #initial ratio\n",
        " \n",
        "    #scale to desired face size\n",
        "    if (boxes is not None):\n",
        "      if len(boxes)>0:\n",
        "        ratio = target_face/max(boxes[0][2:]-boxes[0][:2]); \n",
        "        ratio = min(ratio, max_upscale)\n",
        "        if VERBOSE: print('up by', ratio)\n",
        "\n",
        "    if fixed_ratio>0:\n",
        "      if VERBOSE: print('fixed ratio')\n",
        "      ratio = fixed_ratio\n",
        " \n",
        "    x*=ratio\n",
        "    y*=ratio\n",
        " \n",
        "    #downscale to fit into max res \n",
        "    res = x*y\n",
        "    if res > max_res:\n",
        "      ratio = pow(res/max_res,1/2); \n",
        "      if VERBOSE: print(ratio)\n",
        "      x=int(x/ratio)\n",
        "      y=int(y/ratio)\n",
        " \n",
        "    #make dimensions even, because usually NNs fail on uneven dimensions due skip connection size mismatch\n",
        "    x = makeEven(int(x))\n",
        "    y = makeEven(int(y))\n",
        "    \n",
        "    size = (x, y)\n",
        "\n",
        "    return _img.resize(size)\n",
        "\n",
        "\"\"\" \n",
        "    A useful scaler algorithm, based on face detection.\n",
        "    Takes PIL.Image, returns a uniformly scaled PIL.Image\n",
        "    boxes: a list of detected bboxes\n",
        "    _img: PIL.Image\n",
        "    max_res: maximum pixel area to fit into. Use to stay below the VRAM limits of your GPU.\n",
        "    target_face: desired face size. Upscale or downscale the whole image to fit the detected face into that dimension.\n",
        "    fixed_ratio: fixed scale. Ignores the face size, but doesn't ignore the max_res limit.\n",
        "    max_upscale: maximum upscale ratio. Prevents from scaling images with tiny faces to a blurry mess.\n",
        "\"\"\"\n",
        "\n",
        "def scale_by_face_size(_img, max_res=1_500_000, target_face=256, fix_ratio=0, max_upscale=2, VERBOSE=False):\n",
        "    boxes = None\n",
        "    boxes, _ = detect(_img)\n",
        "    if VERBOSE: print('boxes',boxes)\n",
        "    img_resized = scale(boxes, _img, max_res, target_face, fix_ratio, max_upscale, VERBOSE)\n",
        "    return img_resized\n",
        "\n",
        "\n",
        "size = 256\n",
        "\n",
        "means = [0.485, 0.456, 0.406]\n",
        "stds = [0.229, 0.224, 0.225]\n",
        "\n",
        "t_stds = torch.tensor(stds).cuda().half()[:,None,None]\n",
        "t_means = torch.tensor(means).cuda().half()[:,None,None]\n",
        "\n",
        "def makeEven(_x):\n",
        "  return int(_x) if (_x % 2 == 0) else int(_x+1)\n",
        "\n",
        "img_transforms = transforms.Compose([                        \n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize(means,stds)])\n",
        " \n",
        "def tensor2im(var):\n",
        "     return var.mul(t_stds).add(t_means).mul(255.).clamp(0,255).permute(1,2,0)\n",
        "\n",
        "def proc_pil_img(input_image, model):\n",
        "    transformed_image = img_transforms(input_image)[None,...].cuda().half()\n",
        "            \n",
        "    with torch.no_grad():\n",
        "        result_image = model(transformed_image)[0]; print(result_image.shape)\n",
        "        output_image = tensor2im(result_image)\n",
        "        output_image = output_image.detach().cpu().numpy().astype('uint8')\n",
        "        output_image = PIL.Image.fromarray(output_image)\n",
        "    return output_image\n",
        "\n",
        "#load model\n",
        "\n",
        "version = '0.3' #@param ['0.1','0.2','0.3']\n",
        "\n",
        "model_path = f'/content/ArcaneGANv{version}.jit' \n",
        "in_dir = '/content/in'\n",
        "out_dir = f\"/content/{model_path.split('/')[-1][:-4]}_out\"\n",
        "\n",
        "model = torch.jit.load(model_path).eval().cuda().half()\n",
        "\n",
        "#setup colab interface\n",
        "\n",
        "from google.colab import files\n",
        "import ipywidgets as widgets\n",
        "from IPython.display import clear_output \n",
        "from IPython.display import display\n",
        "import os\n",
        "from glob import glob\n",
        "\n",
        "def reset(p):\n",
        "  with output_reset:\n",
        "    clear_output()\n",
        "  clear_output()\n",
        "  process()\n",
        " \n",
        "button_reset = widgets.Button(description=\"Upload\")\n",
        "output_reset = widgets.Output()\n",
        "button_reset.on_click(reset)\n",
        "\n",
        "def fit(img,maxsize=512):\n",
        "  maxdim = max(*img.size)\n",
        "  if maxdim>maxsize:\n",
        "    ratio = maxsize/maxdim\n",
        "    x,y = img.size\n",
        "    size = (int(x*ratio),int(y*ratio)) \n",
        "    img = img.resize(size)\n",
        "  return img\n",
        " \n",
        "def show_img(f, size=1024):\n",
        "  display(fit(PIL.Image.open(f),size))\n",
        "\n",
        "def process(upload=True):\n",
        "  os.makedirs(in_dir, exist_ok=True)\n",
        "  %cd {in_dir}/\n",
        "  !rm -rf {out_dir}/*\n",
        "  os.makedirs(out_dir, exist_ok=True)\n",
        "  in_files = sorted(glob(f'{in_dir}/*'))\n",
        "  if (len(in_files)==0) | (upload):\n",
        "    !rm -rf {in_dir}/*\n",
        "    uploaded = files.upload()\n",
        "    if len(uploaded.keys())<=0: \n",
        "      print('\\nNo files were uploaded. Try again..\\n')\n",
        "      return\n",
        "\n",
        "  \n",
        "\n",
        "  print('\\nPress the button and pick some photos to upload\\n')\n",
        "  \n",
        "  in_files = sorted(glob(f'{in_dir}/*'))\n",
        "  for img in tqdm(in_files):\n",
        "    out = f\"{out_dir}/{img.split('/')[-1].split('.')[0]}.jpg\"\n",
        "    im = PIL.Image.open(img)\n",
        "    im = scale_by_face_size(im, target_face=300, max_res=1_500_000, max_upscale=2)\n",
        "    res = proc_pil_img(im, model)\n",
        "    res.save(out)\n",
        "\n",
        "  out_zip = f\"{out_dir}.zip\"\n",
        "  !zip {out_zip} {out_dir}/*\n",
        "    \n",
        "  processed = sorted(glob(f'{out_dir}/*'))[:3]\n",
        "  for f in processed: \n",
        "    show_img(f, 256)\n"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tdePnlXFX7x8"
      },
      "source": [
        "#@title Click to upload files and run inference. Results will be saved and zipped.\n",
        "# process()"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "im = PIL.Image.open('/content/imgpsh_mobile_save-4.jpg')\n",
        "res = proc_pil_img(im, model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iOXOcFMMYwNF",
        "outputId": "5cbb625e-1e40-4fcf-c36c-28bc7ae7f49b"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([3, 1124, 1500])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "transformed_image = img_transforms(im)[None,...].cuda().half()\n",
        "transformed_image.shape, transformed_image.type()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L5FmRRbMbYBO",
        "outputId": "b092c969-3707-41b9-c72f-99f303b341cd"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([1, 3, 1124, 1500]), 'torch.cuda.HalfTensor')"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with torch.no_grad():\n",
        "    result_image = model(transformed_image)[0]; print(result_image.shape)\n",
        "    output_image = tensor2im(result_image)\n",
        "    output_image = output_image.detach().cpu().numpy().astype('uint8')\n",
        "    output_image = PIL.Image.fromarray(output_image)\n",
        "# output_image"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5zF8O-C7Zj4d",
        "outputId": "999cbeb6-55f6-4f79-c581-3da0b861156f"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([3, 1124, 1500])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install coremltools"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4TyP3BEscU8M",
        "outputId": "684b1806-66e2-4dd3-c01b-8290c085842c"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting coremltools\n",
            "  Downloading coremltools-5.1.0-cp37-none-manylinux1_x86_64.whl (1.6 MB)\n",
            "\u001b[?25l\r\u001b[K     |▏                               | 10 kB 23.2 MB/s eta 0:00:01\r\u001b[K     |▍                               | 20 kB 28.4 MB/s eta 0:00:01\r\u001b[K     |▋                               | 30 kB 26.7 MB/s eta 0:00:01\r\u001b[K     |▉                               | 40 kB 19.9 MB/s eta 0:00:01\r\u001b[K     |█                               | 51 kB 16.0 MB/s eta 0:00:01\r\u001b[K     |█▎                              | 61 kB 13.1 MB/s eta 0:00:01\r\u001b[K     |█▌                              | 71 kB 13.2 MB/s eta 0:00:01\r\u001b[K     |█▊                              | 81 kB 14.5 MB/s eta 0:00:01\r\u001b[K     |██                              | 92 kB 14.8 MB/s eta 0:00:01\r\u001b[K     |██                              | 102 kB 13.7 MB/s eta 0:00:01\r\u001b[K     |██▎                             | 112 kB 13.7 MB/s eta 0:00:01\r\u001b[K     |██▌                             | 122 kB 13.7 MB/s eta 0:00:01\r\u001b[K     |██▊                             | 133 kB 13.7 MB/s eta 0:00:01\r\u001b[K     |███                             | 143 kB 13.7 MB/s eta 0:00:01\r\u001b[K     |███▏                            | 153 kB 13.7 MB/s eta 0:00:01\r\u001b[K     |███▍                            | 163 kB 13.7 MB/s eta 0:00:01\r\u001b[K     |███▋                            | 174 kB 13.7 MB/s eta 0:00:01\r\u001b[K     |███▉                            | 184 kB 13.7 MB/s eta 0:00:01\r\u001b[K     |████                            | 194 kB 13.7 MB/s eta 0:00:01\r\u001b[K     |████▏                           | 204 kB 13.7 MB/s eta 0:00:01\r\u001b[K     |████▍                           | 215 kB 13.7 MB/s eta 0:00:01\r\u001b[K     |████▋                           | 225 kB 13.7 MB/s eta 0:00:01\r\u001b[K     |████▉                           | 235 kB 13.7 MB/s eta 0:00:01\r\u001b[K     |█████                           | 245 kB 13.7 MB/s eta 0:00:01\r\u001b[K     |█████▎                          | 256 kB 13.7 MB/s eta 0:00:01\r\u001b[K     |█████▌                          | 266 kB 13.7 MB/s eta 0:00:01\r\u001b[K     |█████▊                          | 276 kB 13.7 MB/s eta 0:00:01\r\u001b[K     |██████                          | 286 kB 13.7 MB/s eta 0:00:01\r\u001b[K     |██████▏                         | 296 kB 13.7 MB/s eta 0:00:01\r\u001b[K     |██████▎                         | 307 kB 13.7 MB/s eta 0:00:01\r\u001b[K     |██████▌                         | 317 kB 13.7 MB/s eta 0:00:01\r\u001b[K     |██████▊                         | 327 kB 13.7 MB/s eta 0:00:01\r\u001b[K     |███████                         | 337 kB 13.7 MB/s eta 0:00:01\r\u001b[K     |███████▏                        | 348 kB 13.7 MB/s eta 0:00:01\r\u001b[K     |███████▍                        | 358 kB 13.7 MB/s eta 0:00:01\r\u001b[K     |███████▋                        | 368 kB 13.7 MB/s eta 0:00:01\r\u001b[K     |███████▉                        | 378 kB 13.7 MB/s eta 0:00:01\r\u001b[K     |████████                        | 389 kB 13.7 MB/s eta 0:00:01\r\u001b[K     |████████▏                       | 399 kB 13.7 MB/s eta 0:00:01\r\u001b[K     |████████▍                       | 409 kB 13.7 MB/s eta 0:00:01\r\u001b[K     |████████▋                       | 419 kB 13.7 MB/s eta 0:00:01\r\u001b[K     |████████▉                       | 430 kB 13.7 MB/s eta 0:00:01\r\u001b[K     |█████████                       | 440 kB 13.7 MB/s eta 0:00:01\r\u001b[K     |█████████▎                      | 450 kB 13.7 MB/s eta 0:00:01\r\u001b[K     |█████████▌                      | 460 kB 13.7 MB/s eta 0:00:01\r\u001b[K     |█████████▊                      | 471 kB 13.7 MB/s eta 0:00:01\r\u001b[K     |██████████                      | 481 kB 13.7 MB/s eta 0:00:01\r\u001b[K     |██████████▏                     | 491 kB 13.7 MB/s eta 0:00:01\r\u001b[K     |██████████▎                     | 501 kB 13.7 MB/s eta 0:00:01\r\u001b[K     |██████████▌                     | 512 kB 13.7 MB/s eta 0:00:01\r\u001b[K     |██████████▊                     | 522 kB 13.7 MB/s eta 0:00:01\r\u001b[K     |███████████                     | 532 kB 13.7 MB/s eta 0:00:01\r\u001b[K     |███████████▏                    | 542 kB 13.7 MB/s eta 0:00:01\r\u001b[K     |███████████▍                    | 552 kB 13.7 MB/s eta 0:00:01\r\u001b[K     |███████████▋                    | 563 kB 13.7 MB/s eta 0:00:01\r\u001b[K     |███████████▉                    | 573 kB 13.7 MB/s eta 0:00:01\r\u001b[K     |████████████                    | 583 kB 13.7 MB/s eta 0:00:01\r\u001b[K     |████████████▎                   | 593 kB 13.7 MB/s eta 0:00:01\r\u001b[K     |████████████▍                   | 604 kB 13.7 MB/s eta 0:00:01\r\u001b[K     |████████████▋                   | 614 kB 13.7 MB/s eta 0:00:01\r\u001b[K     |████████████▉                   | 624 kB 13.7 MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 634 kB 13.7 MB/s eta 0:00:01\r\u001b[K     |█████████████▎                  | 645 kB 13.7 MB/s eta 0:00:01\r\u001b[K     |█████████████▌                  | 655 kB 13.7 MB/s eta 0:00:01\r\u001b[K     |█████████████▊                  | 665 kB 13.7 MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 675 kB 13.7 MB/s eta 0:00:01\r\u001b[K     |██████████████▏                 | 686 kB 13.7 MB/s eta 0:00:01\r\u001b[K     |██████████████▍                 | 696 kB 13.7 MB/s eta 0:00:01\r\u001b[K     |██████████████▌                 | 706 kB 13.7 MB/s eta 0:00:01\r\u001b[K     |██████████████▊                 | 716 kB 13.7 MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 727 kB 13.7 MB/s eta 0:00:01\r\u001b[K     |███████████████▏                | 737 kB 13.7 MB/s eta 0:00:01\r\u001b[K     |███████████████▍                | 747 kB 13.7 MB/s eta 0:00:01\r\u001b[K     |███████████████▋                | 757 kB 13.7 MB/s eta 0:00:01\r\u001b[K     |███████████████▉                | 768 kB 13.7 MB/s eta 0:00:01\r\u001b[K     |████████████████                | 778 kB 13.7 MB/s eta 0:00:01\r\u001b[K     |████████████████▎               | 788 kB 13.7 MB/s eta 0:00:01\r\u001b[K     |████████████████▍               | 798 kB 13.7 MB/s eta 0:00:01\r\u001b[K     |████████████████▋               | 808 kB 13.7 MB/s eta 0:00:01\r\u001b[K     |████████████████▉               | 819 kB 13.7 MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 829 kB 13.7 MB/s eta 0:00:01\r\u001b[K     |█████████████████▎              | 839 kB 13.7 MB/s eta 0:00:01\r\u001b[K     |█████████████████▌              | 849 kB 13.7 MB/s eta 0:00:01\r\u001b[K     |█████████████████▊              | 860 kB 13.7 MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 870 kB 13.7 MB/s eta 0:00:01\r\u001b[K     |██████████████████▏             | 880 kB 13.7 MB/s eta 0:00:01\r\u001b[K     |██████████████████▍             | 890 kB 13.7 MB/s eta 0:00:01\r\u001b[K     |██████████████████▌             | 901 kB 13.7 MB/s eta 0:00:01\r\u001b[K     |██████████████████▊             | 911 kB 13.7 MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 921 kB 13.7 MB/s eta 0:00:01\r\u001b[K     |███████████████████▏            | 931 kB 13.7 MB/s eta 0:00:01\r\u001b[K     |███████████████████▍            | 942 kB 13.7 MB/s eta 0:00:01\r\u001b[K     |███████████████████▋            | 952 kB 13.7 MB/s eta 0:00:01\r\u001b[K     |███████████████████▉            | 962 kB 13.7 MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 972 kB 13.7 MB/s eta 0:00:01\r\u001b[K     |████████████████████▎           | 983 kB 13.7 MB/s eta 0:00:01\r\u001b[K     |████████████████████▌           | 993 kB 13.7 MB/s eta 0:00:01\r\u001b[K     |████████████████████▋           | 1.0 MB 13.7 MB/s eta 0:00:01\r\u001b[K     |████████████████████▉           | 1.0 MB 13.7 MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 1.0 MB 13.7 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▎          | 1.0 MB 13.7 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▌          | 1.0 MB 13.7 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▊          | 1.1 MB 13.7 MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 1.1 MB 13.7 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▏         | 1.1 MB 13.7 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▍         | 1.1 MB 13.7 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▌         | 1.1 MB 13.7 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▊         | 1.1 MB 13.7 MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 1.1 MB 13.7 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▏        | 1.1 MB 13.7 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▍        | 1.1 MB 13.7 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▋        | 1.1 MB 13.7 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▉        | 1.2 MB 13.7 MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 1.2 MB 13.7 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 1.2 MB 13.7 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▌       | 1.2 MB 13.7 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▋       | 1.2 MB 13.7 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▉       | 1.2 MB 13.7 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 1.2 MB 13.7 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▎      | 1.2 MB 13.7 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▌      | 1.2 MB 13.7 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▊      | 1.2 MB 13.7 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 1.3 MB 13.7 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▏     | 1.3 MB 13.7 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▍     | 1.3 MB 13.7 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▋     | 1.3 MB 13.7 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▊     | 1.3 MB 13.7 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 1.3 MB 13.7 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▏    | 1.3 MB 13.7 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▍    | 1.3 MB 13.7 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▋    | 1.3 MB 13.7 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▉    | 1.4 MB 13.7 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 1.4 MB 13.7 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▎   | 1.4 MB 13.7 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▌   | 1.4 MB 13.7 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▊   | 1.4 MB 13.7 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▉   | 1.4 MB 13.7 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 1.4 MB 13.7 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▎  | 1.4 MB 13.7 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▌  | 1.4 MB 13.7 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▊  | 1.4 MB 13.7 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 1.5 MB 13.7 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▏ | 1.5 MB 13.7 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▍ | 1.5 MB 13.7 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▋ | 1.5 MB 13.7 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▊ | 1.5 MB 13.7 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 1.5 MB 13.7 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▏| 1.5 MB 13.7 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▍| 1.5 MB 13.7 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▋| 1.5 MB 13.7 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▉| 1.5 MB 13.7 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 1.6 MB 13.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from coremltools) (21.3)\n",
            "Requirement already satisfied: numpy>=1.14.5 in /usr/local/lib/python3.7/dist-packages (from coremltools) (1.19.5)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.7/dist-packages (from coremltools) (1.7.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from coremltools) (4.62.3)\n",
            "Requirement already satisfied: protobuf>=3.1.0 in /usr/local/lib/python3.7/dist-packages (from coremltools) (3.17.3)\n",
            "Requirement already satisfied: six>=1.9 in /usr/local/lib/python3.7/dist-packages (from protobuf>=3.1.0->coremltools) (1.15.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->coremltools) (3.0.6)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.7/dist-packages (from sympy->coremltools) (1.2.1)\n",
            "Installing collected packages: coremltools\n",
            "Successfully installed coremltools-5.1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import coremltools"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "08Sh4kn4k42t",
        "outputId": "c10ebdd6-aa48-432d-b6f4-d13cf6382960"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:scikit-learn version 1.0.1 is not supported. Minimum required version: 0.17. Maximum required version: 0.19.2. Disabling scikit-learn conversion API.\n",
            "WARNING:root:TensorFlow version 2.7.0 has not been tested with coremltools. You may run into unexpected errors. TensorFlow 2.5.0 is the most recent version that has been tested.\n",
            "WARNING:root:Keras version 2.7.0 has not been tested with coremltools. You may run into unexpected errors. Keras 2.2.4 is the most recent version that has been tested.\n",
            "WARNING:root:Torch version 1.10.0+cu111 has not been tested with coremltools. You may run into unexpected errors. Torch 1.9.1 is the most recent version that has been tested.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "image_size = 1024\n",
        "image = torch.randn(1, 3, image_size, image_size).type(torch.cuda.HalfTensor).cuda()\n",
        "# model = model.cpu()\n",
        "# output = model(image)\n",
        "\n",
        "# scripted_model = torch.jit.script(model)\n",
        "# traced = torch.jit.trace(model, image)\n"
      ],
      "metadata": {
        "id": "e6izgVxUk-Q5"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# model = torch.nn.utils.remove_weight_norm(model)"
      ],
      "metadata": {
        "id": "9whwCmKTu74q"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from coremltools.converters.mil import register_torch_op\n",
        "from coremltools.converters.mil.frontend.torch.ops import _get_inputs\n",
        "from coremltools.converters.mil.mil import Builder as mb\n",
        "\n",
        "@register_torch_op\n",
        "def mv(context, node):\n",
        "    inputs = _get_inputs(context, node, expected=2)\n",
        "    expand = mb.expand_dims(x=inputs[1], axes=[-1], name=node.name + \"_expanded\")\n",
        "    mv = mb.matmul(x=inputs[0], y=expand, name=node.name + \"_mv\")\n",
        "    res = mb.squeeze(x=mv, axes=[-1], name=node.name)\n",
        "    context.add(res)\n",
        "\n",
        "@register_torch_op\n",
        "def dot(context, node):\n",
        "    inputs = _get_inputs(context, node, expected=2)\n",
        "    xy = mb.mul(x=inputs[0], y=inputs[1])\n",
        "    sum_xy = mb.reduce_sum(x=xy, axes=[0])\n",
        "    context.add(sum_xy, node.name)\n",
        "\n",
        "@register_torch_op\n",
        "def _weight_norm(context, node):\n",
        "    inputs = _get_inputs(context, node, expected=3)\n",
        "    context.add(inputs[0], node.name)\n"
      ],
      "metadata": {
        "id": "3rWzo1Nayaix"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# image_input = coremltools.ImageType(name=\"input_1\", shape=(1, 3, image_size, image_size))\n",
        "image_input = coremltools.TensorType(shape=image.shape)\n",
        "\n",
        "with torch.inference_mode():\n",
        "  mlmodel = coremltools.converters.convert(\n",
        "    model,\n",
        "    inputs=[image_input],\n",
        "    # minimum_deployment_target=coremltools.target.iOS15,\n",
        "    compute_units=coremltools.ComputeUnit.ALL,\n",
        "    convert_to=\"neuralnetwork\", # \"mlprogram\" \"neuralnetwork\"\n",
        "    # compute_precision=coremltools.precision.FLOAT16\n",
        "  )\n",
        "\n",
        "  mlmodel"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h4yVY4AClrnu",
        "outputId": "eda1d6be-f596-4e61-c380-b3372fd96392"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Converting Frontend ==> MIL Ops: 100%|█████████▉| 585/586 [00:00<00:00, 824.72 ops/s]\n",
            "Running MIL Common passes:   0%|          | 0/34 [00:00<?, ? passes/s]/usr/local/lib/python3.7/dist-packages/coremltools/converters/mil/mil/passes/name_sanitization_utils.py:101: UserWarning: Input, 'x.5', of the source model, has been renamed to 'x_5' in the Core ML model.\n",
            "  warnings.warn(msg.format(var.name, new_name))\n",
            "/usr/local/lib/python3.7/dist-packages/coremltools/converters/mil/mil/passes/name_sanitization_utils.py:129: UserWarning: Output, '1093', of the source model, has been renamed to 'var_1093' in the Core ML model.\n",
            "  warnings.warn(msg.format(var.name, new_name))\n",
            "Running MIL Common passes: 100%|██████████| 34/34 [00:01<00:00, 23.32 passes/s]\n",
            "Running MIL Clean up passes: 100%|██████████| 9/9 [00:00<00:00, 14.30 passes/s]\n",
            "Translating MIL ==> NeuralNetwork Ops: 100%|██████████| 611/611 [00:06<00:00, 89.84 ops/s] \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mlmodel"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HptpJ8ajluv5",
        "outputId": "b2918f49-2ab2-40c4-c74c-27c4c50234f6"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "input {\n",
              "  name: \"x_5\"\n",
              "  type {\n",
              "    multiArrayType {\n",
              "      shape: 1\n",
              "      shape: 3\n",
              "      shape: 1024\n",
              "      shape: 1024\n",
              "      dataType: FLOAT32\n",
              "    }\n",
              "  }\n",
              "}\n",
              "output {\n",
              "  name: \"var_1093\"\n",
              "  type {\n",
              "    multiArrayType {\n",
              "      dataType: FLOAT32\n",
              "    }\n",
              "  }\n",
              "}\n",
              "metadata {\n",
              "  userDefined {\n",
              "    key: \"com.github.apple.coremltools.source\"\n",
              "    value: \"torch==1.10.0+cu111\"\n",
              "  }\n",
              "  userDefined {\n",
              "    key: \"com.github.apple.coremltools.version\"\n",
              "    value: \"5.1.0\"\n",
              "  }\n",
              "}"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "class Wrapper(torch.nn.Module):\n",
        "    def __init__(self, model):\n",
        "        super().__init__()\n",
        "        self.model = model\n",
        "        \n",
        "    def forward(self, input):\n",
        "        # input = input.view(1, 3, 1024, 1024)\n",
        "        input = input / 127.5 - 1\n",
        "\n",
        "        out = self.model(input)\n",
        "\n",
        "        # out = out[0]\n",
        "        out = (out + 1) * 127.5\n",
        "        out = out.clamp(0.0, 255.0)\n",
        "\n",
        "        return out"
      ],
      "metadata": {
        "id": "hwcB1nDTrHf0"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image_size = 1024\n",
        "image = torch.randn(1, 3, image_size, image_size).type(torch.HalfTensor).cuda()\n",
        "\n",
        "wrapper = Wrapper(model.cpu())\n",
        "# output = wrapper(image)\n",
        "\n",
        "scripted_model = torch.jit.script(wrapper)\n",
        "# traced = torch.jit.trace(wrapper, image)\n"
      ],
      "metadata": {
        "id": "1DJRNp6hsBcD"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image_input = coremltools.ImageType(name=\"input_99\", shape=(1, 3, image_size, image_size))\n",
        "# image_input = coremltools.TensorType(shape=image.shape)\n",
        "\n",
        "mlmodel = coremltools.converters.convert(\n",
        "  scripted_model,\n",
        "  inputs=[image_input],\n",
        "  # minimum_deployment_target=coremltools.target.iOS15,\n",
        "  compute_units=coremltools.ComputeUnit.ALL,\n",
        "  convert_to=\"neuralnetwork\", # \"mlprogram\" \"neuralnetwork\"\n",
        "  # compute_precision=coremltools.precision.FLOAT16\n",
        ")\n",
        "\n",
        "mlmodel"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fOqlMqeFsofm",
        "outputId": "214ed5ba-713f-4a9c-bb20-b46fd928a117"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Converting Frontend ==> MIL Ops: 100%|█████████▉| 536/537 [00:00<00:00, 838.86 ops/s]\n",
            "Running MIL Common passes:   0%|          | 0/34 [00:00<?, ? passes/s]/usr/local/lib/python3.7/dist-packages/coremltools/converters/mil/mil/passes/name_sanitization_utils.py:129: UserWarning: Output, 'out.25', of the source model, has been renamed to 'out_25' in the Core ML model.\n",
            "  warnings.warn(msg.format(var.name, new_name))\n",
            "Running MIL Common passes: 100%|██████████| 34/34 [00:01<00:00, 23.21 passes/s]\n",
            "Running MIL Clean up passes: 100%|██████████| 9/9 [00:00<00:00, 14.05 passes/s]\n",
            "Translating MIL ==> NeuralNetwork Ops: 100%|██████████| 604/604 [00:06<00:00, 87.57 ops/s]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "input {\n",
              "  name: \"input_99\"\n",
              "  type {\n",
              "    imageType {\n",
              "      width: 1024\n",
              "      height: 1024\n",
              "      colorSpace: RGB\n",
              "    }\n",
              "  }\n",
              "}\n",
              "output {\n",
              "  name: \"out_25\"\n",
              "  type {\n",
              "    multiArrayType {\n",
              "      dataType: FLOAT32\n",
              "    }\n",
              "  }\n",
              "}\n",
              "metadata {\n",
              "  userDefined {\n",
              "    key: \"com.github.apple.coremltools.source\"\n",
              "    value: \"torch==1.10.0+cu111\"\n",
              "  }\n",
              "  userDefined {\n",
              "    key: \"com.github.apple.coremltools.version\"\n",
              "    value: \"5.1.0\"\n",
              "  }\n",
              "}"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    }
  ]
}